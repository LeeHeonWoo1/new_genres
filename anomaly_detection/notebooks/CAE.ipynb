{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional AutoEncoder를 활용한 이미지 이상탐지\n",
    "\n",
    "이미지의 경우 모두 가로 세로 256px의 산 이미지이며, 산 이미지 = 정상, 구름이 낀 이미지 = 비정상으로 탐지하는 모델을 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = \"../data/normal_data/\"  # 정상 데이터셋 (구름 없음) 경로\n",
    "anomaly_dataset = \"../data/anomaly_data/\"  # 비정상 데이터셋 (구름 있음) 경로\n",
    "\n",
    "target_width = 256  # input shape의 width\n",
    "target_height = 256  # input shape의 height\n",
    "target_channels = 3  # input shape의 channel\n",
    "epochs = 300  # 학습 횟수\n",
    "batch_size = 16  # batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator.flow_from_directory\n",
    "\n",
    "`ImageDataGenerator.flow_from_directory`의 class_mode를 활용하면 Auto Encoder에 활용하는 데이터셋의 형태로 format을 변경할 수 있다.\n",
    "\n",
    "그간 사용했던 옵션들의 경우 아래와 같다.\n",
    "- `class_mode=\"binary\"` : 이미지 분류 문제 중, 이진 분류 문제를 다룰 때 사용한다.\n",
    "- `class_mode=\"categorical\"` : 이미지 분류 문제 중, 다중 분류 문제를 다룰 때 사용한다. multi-labeled이며, one-hot encoding된 상태를 의미한다.\n",
    "\n",
    "나머지 옵션들은 아래와 같다.\n",
    "- `class_mode='input'` : Auto Encoder를 사용해야 할 때 사용한다. 데이터셋의 input과 output을 동일하게 만들어준다고 한다.\n",
    "- `class_mode='sparse'` : 이미지 분류 문제 중, 다중 분류 문제를 다룰 때 사용하는데, multi-label된 형태이며, label encoding된 형태라고 한다.\n",
    "- `class_mode='None'` : 말 그대로 클래스 모드가 없음을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,  # 정규화\n",
    "    validation_split=0.3  # validation split factor\n",
    ")\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255,  # test셋은 정규화만, \n",
    ")\n",
    "\n",
    "train_dataset = train_generator.flow_from_directory(\n",
    "    normal_dataset,  # 데이터셋 경로\n",
    "    classes=None,  # 단일 클래스를 기반으로 학습을 진행하기에 None으로,\n",
    "    class_mode='input',  # Auto Encoder에 자주 활용되는 input mode로,\n",
    "    color_mode=\"rgb\",  # 컬러 이미지\n",
    "    batch_size=batch_size,  # batch size\n",
    "    target_size=(target_width, target_height),  # target size\n",
    "    subset=\"training\",\n",
    "    seed=1337  # validation split을 사용하고 있기에, 반드시 필요하다. 또한, validation set과 동일하게 설정되어야 한다.\n",
    ")\n",
    "\n",
    "valid_dataset = train_generator.flow_from_directory(\n",
    "    normal_dataset,\n",
    "    classes=None,\n",
    "    class_mode='input',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    target_size=(target_height, target_width),\n",
    "    subset=\"validation\",\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "test_dataset = test_generator.flow_from_directory(\n",
    "    anomaly_dataset,\n",
    "    classes=None,\n",
    "    class_mode='input',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    target_size=(target_height, target_width),\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Auto Encoder\n",
    "\n",
    "AutoEncoder의 경우 이상탐지에 자주 사용되는 모델인데, 이미지 처리에 탁월한 Convolutional layer와 결합하면 이미지에 대해서 정상/비정상 검출이 가능하지 않을까? 하는 마음에 시도해봤다.\n",
    "\n",
    "### Encoder\n",
    "Encoder의 경우 Convolution연산 후 Pooling을 수행하면서 이미지로부터 Feature를 추출하며 다운 샘플링을 진행한다. 다운 샘플링이 완료된 시점에서는 input되는 이미지들에 대한 저차원 특성 벡터가 생성된다.\n",
    "\n",
    "### Decoder\n",
    "Decoder의 경우 Encoder와는 반대로 업 샘플링(역 합성곱 연산)을 진행하는데, 이 때 사용되는 Conv2DTranspose는 up-sampling을 진행함과 동시에 <span style=\"background-color: yellow;\">학습 가능한 필터</span>를 사용하여 보다 원활한 이미지 복구가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "input_layer = Input(shape=(target_height, target_width, target_channels))\n",
    "x = Conv2D(64, (3, 3), padding=\"same\")(input_layer)  # (256, 256, 64)\n",
    "x = BatchNormalization()(x)  # 상황에 따라 다르지만, BatchNorm은 항상 Activation을 거치기 전에.\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2),padding=\"valid\")(x)  # (128, 128, 64)\n",
    "x = Conv2D(128, (3, 3), padding=\"same\")(x)  # (128, 128, 128)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2),padding=\"valid\")(x)  # (64, 64, 128)\n",
    "x = Conv2D(256, (3, 3), padding=\"same\")(x)  # (64, 64, 256)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2),padding=\"valid\")(x)  # (32, 32, 256)\n",
    "x = Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded = Activation(\"relu\")(x)\n",
    "\n",
    "# Decoder\n",
    "decoded = Conv2DTranspose(512, (3, 3), padding=\"same\")(encoded)  # Conv2DTranspose 사용\n",
    "x = BatchNormalization()(decoded)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2DTranspose(256, (3, 3), padding=\"same\", strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2DTranspose(128, (3, 3), padding=\"same\", strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = Conv2DTranspose(64, (3, 3), padding=\"same\", strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "output_layer = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer = \"adam\", loss=\"mse\")\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=5, factor=0.1, mode=\"min\")\n",
    "\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, callbacks=[early_stop, reduce_lr])\n",
    "model.save(\"./models/weights/my_autoencoder.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Error\n",
    "현재 학습된 모델의 경우 데이터셋은 오로지 **정상 데이터셋**으로만 학습되었다. 어떻게 특정 기준을 기반으로 정상/비정상을 탐지할까?\n",
    "\n",
    "그건 바로 <span style=\"background-color: yellow;\">재구성 오류(Reconstruction Error)</span>를 기반으로 임계치를 설정하여, 임계치보다 큰 이미지의 경우 비정상으로 분류한다.\n",
    "\n",
    "여기서 Reconstruction error란, input되는 image vector와 decoder의 output으로 나온 재구성된 이미지 벡터(reconstructed image vector)간의 차이를 의미한다. \n",
    "\n",
    "따라서 임계치에 대한 기준을 잡기 위해서 training에 사용된 모든 이미지의 reconstruction error의 histogram과 비정상 이미지의 reconstruction error histogram을 기반으로 임계치를 정해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정상 데이터의 재구성 오류값의 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_errors = []\n",
    "normal_image_filenames = glob(\"../data/normal_data/*/*\")\n",
    "\n",
    "for filename in normal_image_filenames:  # 이미지 경로 하나하나를 순회하면서\n",
    "    image = Image.open(filename).convert(\"RGB\")  # 이미지를 open하되, rgba가 아니라 rgb모드로 열어서\n",
    "    nd_image = np.expand_dims((np.array(image)/255), axis=0)  # batch 단위 표현을 위해 차원을 확장하고\n",
    "    image_array = tf.cast(nd_image, dtype=tf.float32)  # float32형으로 변환하여\n",
    "    reconstructed_image = model.predict(image_array, verbose=0)  # 예측을 수행한다.\n",
    "    \n",
    "    reconstructed_error = np.mean(np.square(image_array - reconstructed_image))  # mse를 활용하여 reconstruction error를 계산하고\n",
    "    reconstruction_errors.append(reconstructed_error)  # 배열에 담아서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(reconstruction_errors)  # 히스토그램으로 시각화한다.\n",
    "fig.update_layout(width=800, height=600)  # layout 크기 조절\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비정상 데이터의 재구성 오류값의 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_reconstruction_errors = []\n",
    "anomaly_image_filenames = glob(\"../data/anomaly_data/*/*\")\n",
    "\n",
    "for filename in anomaly_image_filenames:\n",
    "    image = Image.open(filename).convert(\"RGB\")\n",
    "    nd_image = np.expand_dims((np.array(image)/255), axis=0)\n",
    "    image_array = tf.cast(nd_image/255, dtype=tf.float32)\n",
    "    reconstructed_image = model.predict(image_array, verbose=0)\n",
    "    \n",
    "    reconstructed_error = np.mean(np.square(image_array - reconstructed_image))\n",
    "    anomaly_reconstruction_errors.append(reconstructed_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(anomaly_reconstruction_errors)\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training image들의 reconstruction error histogram을 통해서 학습에 사용된 이미지들의 대다수 이상이 0.005 이내로 재구성 오류값이 분포된 것을 확인할 수 있다.\n",
    "\n",
    "따라서 임계치를 0.0045로 잡고, 비정상 이미지 탐지 결과에 대한 정확도를 표시해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative = len([i for i in anomaly_reconstruction_errors if i > 0.005])  # 재구성 오류값이 임계치, 즉 0.005보다 큰 것들(비정상)\n",
    "all_data = len(anomaly_reconstruction_errors)  # 비정상 데이터의 전체 개수\n",
    "\n",
    "anomaly_detection_acc = true_negative / all_data  # acc 계산\n",
    "anomaly_detection_acc  # 와 ! 100퍼센트 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 재구성된 이미지와, 원본 이미지의 차이를 정상/비정상 분류 결과와 함께 나타내보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.rcParams['font.family'] = \"Malgun Gothic\"  # 그래프 내에서 한글 깨짐 현상 방지\n",
    "anomaly_image_filenames = glob(\"../data/anomaly_data/*/*\")  # 비정상 데이터의 전체 파일 이름들\n",
    "\n",
    "def predict_results(filepath, threshold):\n",
    "    image = Image.open(filepath).convert(\"RGB\")\n",
    "    image_arr = tf.cast((np.array(image)/255), dtype=tf.float32)\n",
    "    img = np.expand_dims(image_arr, axis=0)\n",
    "\n",
    "    reconstructed_image = model.predict(img, verbose=0)\n",
    "    reconstructed_error = np.mean(np.square(img - reconstructed_image))\n",
    "\n",
    "    if reconstructed_error > threshold:\n",
    "        return [\"비정상\", img, reconstructed_image]\n",
    "    else:\n",
    "        return [\"정상\", img, reconstructed_image]\n",
    "\n",
    "def plot_results(filepath, threshold):\n",
    "    message, origin, reconstructed_image = predict_results(filepath, threshold)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(origin[0])\n",
    "    plt.gca().set_title(\"원본 이미지\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reconstructed_image[0])\n",
    "    plt.gca().set_title(f\"예측 이미지 \\n 예측된 결과 : {message}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(anomaly_image_filenames[8], 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(normal_image_filenames[0], 0.004)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
