{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_10928\\1734209592.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  input_batch = torch.Tensor(input_batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, cost = 1.574704\n",
      "Epoch 2000, cost = 1.629581\n",
      "Epoch 3000, cost = 1.130401\n",
      "Epoch 4000, cost = 1.526712\n",
      "Epoch 5000, cost = 1.295940\n",
      "Epoch 6000, cost = 0.663110\n",
      "Epoch 7000, cost = 1.447102\n",
      "Epoch 8000, cost = 1.700677\n",
      "Epoch 9000, cost = 1.355525\n",
      "Epoch 10000, cost = 1.648024\n",
      "Epoch 11000, cost = 1.291069\n",
      "Epoch 12000, cost = 0.959810\n",
      "Epoch 13000, cost = 0.997126\n",
      "Epoch 14000, cost = 1.171757\n",
      "Epoch 15000, cost = 0.700689\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_batch():\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)\n",
    "\n",
    "    for i in random_index:\n",
    "        random_inputs.append(np.eye(voc_size)[skip_grams[i][0]])  # target\n",
    "        random_labels.append(skip_grams[i][1])  # context word\n",
    "\n",
    "    return random_inputs, random_labels\n",
    "\n",
    "# Model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        # W and WY is not Transpose Relationship\n",
    "        self.W = nn.Linear(voc_size, embedding_size, bias=False)  # voc_size > embedding_size Weight\n",
    "        self.WT = nn.Linear(embedding_size, voc_size, bias=False)  # embedding_size > voc_size Weight\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X : [batch_size, voc_size]\n",
    "        hidden_layer = self.W(X)  # hidden_layer : [batch_size, embedding_size]\n",
    "        output_layer = self.WT(hidden_layer)\n",
    "        return output_layer\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    batch_size = 2\n",
    "    embedding_size = 2\n",
    "\n",
    "    sentences = [\"apple banana fruit\", \"banana orange fruit\", 'orange banana fruit', 'dog cat animal', 'cat monkey animal', 'monkey dog animal']\n",
    "\n",
    "    word_sequence = \" \".join(sentences).split()\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w : i for i, w in enumerate(word_list)}\n",
    "    voc_size = len(word_list)\n",
    "\n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    for i in range(1, len(word_sequence) - 1):\n",
    "        target = word_dict[word_sequence[i]]\n",
    "        context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]\n",
    "        for w in context:\n",
    "            skip_grams.append([target, w])\n",
    "    \n",
    "    model = Word2Vec()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(15000):\n",
    "        input_batch, target_batch = random_batch()\n",
    "        input_batch = torch.Tensor(input_batch)\n",
    "        target_batch = torch.LongTensor(target_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_batch)\n",
    "\n",
    "        # output : [batch size, voc size], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "        loss = criterion(output, target_batch)\n",
    "        if (epoch+1)%1000 == 0:\n",
    "            print('Epoch {}, cost = {:.6f}'.format(epoch+1, loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    for i, label in enumerate(word_list):\n",
    "        W, WT = model.parameters()\n",
    "        x, y = W[0][i].item(), W[1][i].item()\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords=\"offset points\", ha=\"right\", va=\"bottom\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링\n",
    "Word2Vec의 출력층에는 소프트맥스 함수를 지난 단어 집합의 크기의 벡터와 실제값인 원핫 벡터와의 오차를 구하고 이로부터 임베딩 벡터 값을 업데이트합니다. 만약 단어 집합의 크기가 수만 이상에 달한다면 이 작업은 굉장히 무거운 작업이므로, Word2Vec은 꽤나 학습하기에 무거운 모델이 됩니다.\n",
    "\n",
    "Word2Vec은 역전파 과정에서 모든 단어의 임베딩 벡터값의 업데이트를 수행하지만, 만약 현재 집중하고 있는 중심 단어와 주변 단어가 '강아지'와 '고양이', '귀여운'과 같은 단어라면, 사실 이 단어들과 별 연관 관계가 없는 '돈가스'나 '컴퓨터'와 같은 수많은 단어의 임베딩 벡터값까지 업데이트하는 것은 비효율적입니다.\n",
    "\n",
    "네거티브 샘플링은 **Word2Vec이 학습 과정에서 전체 단어 집합이 아니라 일부 단어 집합에만 집중할 수 있도록 하는 방법**입니다. 가령 현재 집중하고 있는 주변 단어가 '고양이', '귀여운'이라고 해봅시다. 여기에 '돈가스', '컴퓨터', '회의실'과 같은 단어 집합에서 무작위로 선택된 주변 단어가 아닌 단어들을 일부 가져옵니다. 이렇게 하나의 중심 단어에 대해서 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어 놓고 마지막 단계를 이진 분류 문제로 변환합니다. 주변 단어들을 긍정(positive), 랜덤으로 샘플링 된 단어들을 부정(negative)으로 레이블링한다면 이진 분류 문제를 위한 데이터셋이 됩니다. 이는 기존의 단어 집합의 크기만큼의 선택지를 두고 다중 클래스 분류 문제를 풀던 Word2Vec보다 훨씬 연산량에서 효율적입니다.\n",
    "\n",
    "## 네거티브 샘플링 Skip-gram\n",
    "\n",
    "> The fat cat sat on the mat\n",
    "\n",
    "skip-gram은 중심 단어로부터 주변 단어를 예측하는 모델이다. 위와 같은 문장이 있다고 한다면, Skip-Gram은 중심 단어인 cat으로 부터 주변 단어인 The, sat, on을 예측한다. 기존의 Skip-gram은 입력으로 cat이 주어지고, 예측으로 주변 단어가 output으로 나오는 구조이다.\n",
    "\n",
    "하지만 네거티브 샘플링을 사용하는 Skip-Gram(SGNS)는 이와는 다른 접근 방식을 취합니다. 주변단어와 중심단어가 모두 input으로 입력되고, 이 두 단어가 실제로 window size 내에 존재하는 이웃 관계인지 그 확률을 예측한다.\n",
    "\n",
    "기존의 Skip-gram 데이터셋을 SGNS의 데이터셋으로 바꾸는 과정은 아래와 같다.\n",
    "\n",
    "<img src=\"./images_for_markdown/SGtoSGNS.png\">\n",
    "\n",
    "위의 그림에서 좌측의 테이블은 기존의 skip-gram을 학습하기 위한 데이터셋입니다. Skip-gram은 기본적으로 중심 단어를 입력, 주변 단어를 레이블로 합니다. 하지만 SGNS를 학습하고 싶다면, 이 데이터셋을 우측의 테이블과 같이 수정할 필요가 있습니다. 우선, **기존의 Skip-gram 데이터셋에서 중심 단어와 주변 단어를 각각 입력1, 입력2**로 둡니다. 이 둘은 실제로 윈도우 크기 내에서 이웃 관계였으므로, **레이블은 1**로 합니다. 이제 레이블이 0인 샘플들을 준비할 차례입니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/SGNS-data.png\">\n",
    "\n",
    "실제로는 입력1(중심 단어)와 주변 단어 관계가 아닌 단어들을 입력2로 삼기 위해서 **단어 집합에서 랜덤으로 선택한 단어들을 입력2**로 하고, **레이블을 0**으로 합니다. 이제 이 데이터셋은 입력1과 입력2가 실제로 윈도우 크기 내에서 이웃 관계인 경우에는 레이블이 1, 아닌 경우에는 레이블이 0이 됩니다. 그리고 이제 두 개의 임베딩 테이블을 준비합니다. 두 임베딩 테이블은 훈련 데이터의 단어 집합의 크기를 가지므로 크기가 같습니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding_table.png\">\n",
    "\n",
    "두 테이블 중 하나는 입력1인 중심 단어의 룩업 테이블을 위한 임베딩 테이블이고, 하나는 입력2인 주변 단어의 룩업테이블을 위한 임베딩 테이블입니다. 각 단어는 각 임베딩 테이블을 룩업 테이블하여 임베딩 벡터로 변환됩니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding.png\">\n",
    "\n",
    "각 임베딩 테이블을 통해 룩업 테이블 하며 임베딩 벡터로 변환되었다면 그 후의 연산은 매우 간단합니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding_vec_update.png\">\n",
    "\n",
    "중심 단어와 주변 단어의 내적값을 이 모델의 예측값으로 하고, 레이블과의 오차로부터 역전파 하며 중심 단어와 주변 단어의 임베딩 벡터값을 업데이트합니다. 학습 후에는 좌측의 임베딩 행렬을 임베딩 벡터로 사용할 수도 있고, 두 행렬을 더한 후 사용하거나 두 행렬을 연결(concatenate)해서 사용할 수도 있습니다. 아래의 실습에서는 좌측의 행렬을 사용하는 방식을 택했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20뉴스 그룹 데이터셋으로 실습을 진행합니다. \n",
    "\n",
    "해당 실습에서는 하나의 샘플에 최소 2개의 단어가 있어야합니다. 그래야만 중심 단어, 주변 단어의 관계가 성립하며 그렇지 않으면 샘플을 구성할 수 없어 오류가 발생합니다. 전처리 과정에서 지속적으로 이를 만족하지 않는 샘플들을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "documents = dataset.data\n",
    "print(\"총 샘플 수 : \", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 샘플 수는 11,314개 입니다. 전처리를 진행하며 불필요한 토큰을 제거하고, 소문자화를 통해 정규화를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({\"document\":documents})\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")  # 특수문자 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))  # 길이가 3 이하인 문자들 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().values.any()  # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.replace(\"\", float(\"NaN\"), inplace=True)  # 빈 값을 결측치로 치환해서 다시 확인\n",
    "news_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  11004\n"
     ]
    }
   ],
   "source": [
    "news_df.dropna(inplace=True)  # 결측치 제거\n",
    "print('총 샘플 수 : ', len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stop_words = stopwords.words(\"english\")\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  10961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniconda3\\envs\\mynlp\\lib\\site-packages\\numpy\\lib\\function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)\n",
    "print(\"총 샘플 수 : \", len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {val : key for key, val in word2idx.items()}\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40,\n",
       "  53,\n",
       "  927,\n",
       "  143,\n",
       "  15889,\n",
       "  1684,\n",
       "  546,\n",
       "  279,\n",
       "  871,\n",
       "  12028,\n",
       "  17773,\n",
       "  24007,\n",
       "  29726,\n",
       "  279,\n",
       "  871,\n",
       "  63435,\n",
       "  871,\n",
       "  1128,\n",
       "  1103,\n",
       "  1998,\n",
       "  851,\n",
       "  29727,\n",
       "  913,\n",
       "  731,\n",
       "  20477,\n",
       "  279,\n",
       "  871,\n",
       "  170,\n",
       "  143,\n",
       "  1811,\n",
       "  149,\n",
       "  279,\n",
       "  20478,\n",
       "  17773,\n",
       "  6645,\n",
       "  5710,\n",
       "  76,\n",
       "  63436,\n",
       "  7,\n",
       "  36,\n",
       "  165,\n",
       "  614,\n",
       "  653,\n",
       "  29728,\n",
       "  6911,\n",
       "  24008,\n",
       "  2082,\n",
       "  829,\n",
       "  17774,\n",
       "  1119,\n",
       "  8790,\n",
       "  355,\n",
       "  1072,\n",
       "  15890,\n",
       "  671,\n",
       "  57,\n",
       "  163,\n",
       "  4231,\n",
       "  7206,\n",
       "  1933,\n",
       "  440,\n",
       "  56,\n",
       "  282,\n",
       "  4730,\n",
       "  9275,\n",
       "  2690,\n",
       "  39306],\n",
       " [1283,\n",
       "  429,\n",
       "  3,\n",
       "  52,\n",
       "  6164,\n",
       "  159,\n",
       "  112,\n",
       "  474,\n",
       "  89,\n",
       "  17775,\n",
       "  18,\n",
       "  63,\n",
       "  4731,\n",
       "  2865,\n",
       "  63437,\n",
       "  1042,\n",
       "  402,\n",
       "  39307,\n",
       "  8791,\n",
       "  902,\n",
       "  44,\n",
       "  8328,\n",
       "  316,\n",
       "  13041,\n",
       "  902,\n",
       "  3452,\n",
       "  5923,\n",
       "  533,\n",
       "  18,\n",
       "  87,\n",
       "  4732,\n",
       "  9872,\n",
       "  160,\n",
       "  1403,\n",
       "  120,\n",
       "  151,\n",
       "  5194,\n",
       "  63438,\n",
       "  63439,\n",
       "  17776,\n",
       "  63440,\n",
       "  13041,\n",
       "  903,\n",
       "  63441,\n",
       "  63442,\n",
       "  11172,\n",
       "  17777]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 :  181839\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "\n",
    "print(\"단어 집합의 크기 : \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링을 통한 데이터셋 구성하기\n",
    "\n",
    "토큰화, 정제, 정규화, 불용어 제거, 정수 인코딩까지 일반적인 전처리 과정을 거쳤습니다. 네거티브 샘플링을 통한 데이터셋을 구성할 차례입니다.\n",
    "\n",
    "이를 위해서는 네커티브 샘플링을 위해서 케라스에서 제공하는 전처리 도구인 skipgrams를 사용합니다. 어떤 전처리가 수행되는지 그 결과를 확인하기 위해서 상위 10개의 뉴스 그룹 샘플에 대해서만 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(atrocities. (29728), md6f1o[_':<?'q\\=id;]id;\\oq\\>1:<=i+veiq\\=iqr^1d9$o:9$z.l?':8:1 (153545)) -> 0\n",
      "(ruin (12028), story (927)) -> 1\n",
      "(guilt (7206), blessing (15890)) -> 1\n",
      "(letter (731), seem (143)) -> 1\n",
      "(ignore (1811), subsidizing (20478)) -> 1\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플인 skip_grams[0] 내 skipgrams로 형성된 데이터셋 확인\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "        idx2word[pairs[i][0]], pairs[i][0],\n",
    "        idx2word[pairs[i][1]], pairs[i][1],\n",
    "        labels[i]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윈도우 크기 내에서 중심 단어, 주변 단어의 관계를 가지는 경우에는 1의 레이블을 갖도록 하고, 그렇지 않은 경우는 0의 레이블을 가지도록 하여 데이터셋을 구성합니다.\n",
    "\n",
    "이 과정은 각각의 뉴스그룹 샘플에 대해서 동일한 프로세스로 수행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  10\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 : ', len(skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded 중 상위 10개의 뉴스그룹 샘플에 대해서만 수행하였으므로 10이 출력됩니다. 그리고 10개의 뉴스그룹 샘플 각각은 수많은 중심 단어, 주변 단어의 쌍으로 된 샘플들을 갖고 있습니다. 첫 번째 뉴스그룹 샘플이 가지고 있는 pairs와 labels의 개수를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460\n",
      "2460\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 뉴스그룹 샘플에 대해 수행\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram with Negative Sampling(SGNS) 구현하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터인 임베딩 벡터의 차원은 100으로 정하고, 두 개의 임베딩 층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "# 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype=\"int32\")\n",
    "word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs)\n",
    "\n",
    "# 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype=\"int32\")\n",
    "context_embedding = Embedding(vocab_size, embedding_dim)(c_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 임베딩 테이블은 중심 단어와 주변 단어 각각을 위한 임베딩 테이블이며 각 단어는 임베딩 테이블을 거쳐서 내적을 수행하고, 내적의 결과는 1 또는 0을 예측하기 위해서 시그모이드 함수를 활성화 함수로 거쳐 최종 예측값을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       18183900    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 100)       18183900    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 1)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1)            0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,367,800\n",
      "Trainable params: 36,367,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1, ), input_shape=(1, 1))(dot_product)\n",
    "output = Activation(\"sigmoid\")(dot_product)\n",
    "\n",
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "plot_model(model, to_file=\"model3.png\", show_shapes=True, show_layer_names=True, rankdir=\"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 5592.068294741213\n",
      "Epoch : 2 Loss : 4304.659364938736\n",
      "Epoch : 3 Loss : 4059.000408515334\n",
      "Epoch : 4 Loss : 3757.968439348042\n",
      "Epoch : 5 Loss : 3438.554327165708\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for _, elem in enumerate(skip_grams):\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype=\"int32\")\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype=\"int32\")\n",
    "        labels = np.array(elem[1], dtype=\"int32\")\n",
    "        X = [first_elem, second_elem]\n",
    "        Y = labels\n",
    "\n",
    "        loss += model.train_on_batch(X, Y)\n",
    "    print(\"Epoch : {} Loss : {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "with open('vectors.txt', 'w') as f:\n",
    "    f.write(\"{} {}\\n\".format(vocab_size-1, embedding_dim))\n",
    "\n",
    "    vectors = model.get_weights()[0]\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        f.write('{} {}\\n'.format(word, \" \".join(map(str, list(vectors[i, :])))))\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"./vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('villages', 0.7549866437911987),\n",
       " ('lebanese', 0.6862703561782837),\n",
       " ('murdered', 0.668368935585022),\n",
       " ('territory', 0.6653249859809875),\n",
       " ('occupied', 0.6579276919364929),\n",
       " ('civilians', 0.6509349346160889),\n",
       " ('terrorist', 0.6505898237228394),\n",
       " ('lebanon', 0.6483913660049438),\n",
       " ('aggression', 0.6475304365158081),\n",
       " ('israeli', 0.6383012533187866)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['soldiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autokeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
