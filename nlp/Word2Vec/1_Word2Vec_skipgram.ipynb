{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_11808\\1734209592.py:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  input_batch = torch.Tensor(input_batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, cost = 1.988569\n",
      "Epoch 2000, cost = 2.133668\n",
      "Epoch 3000, cost = 1.563820\n",
      "Epoch 4000, cost = 1.490436\n",
      "Epoch 5000, cost = 1.341902\n",
      "Epoch 6000, cost = 1.179125\n",
      "Epoch 7000, cost = 1.209313\n",
      "Epoch 8000, cost = 1.497668\n",
      "Epoch 9000, cost = 1.039841\n",
      "Epoch 10000, cost = 1.463239\n",
      "Epoch 11000, cost = 2.106416\n",
      "Epoch 12000, cost = 1.511435\n",
      "Epoch 13000, cost = 1.407205\n",
      "Epoch 14000, cost = 1.431393\n",
      "Epoch 15000, cost = 0.595522\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+0klEQVR4nO3deVxVdf7H8fe9KJtsKgiYgGuKueMGLeroBFo0tk27aWalWW7lkqWZU2q5TU5l2iTWWFY/02yjlNRKzQXFMpGEJAxFzeUSmIDc8/vD8U4EEhSXy4HX8/E4j/Gc8/2e87lnrPvunO/5XothGIYAAABMwurqAgAAACqD8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEylnqsLqGp2u12HDx+Wr6+vLBaLq8sBAAAVYBiGfv75ZzVt2lRWa/n3VmpdeDl8+LDCwsJcXQYAAPgDDh06pGbNmpXbptaFF19fX0nnP7yfn5+LqwEAABWRm5ursLAwx/d4eWpdeLnwqMjPz4/wAgCo1QzDUHFxserVqz1f5xUZ8sGAXQAAapCCggI9/PDDatKkiTw9PXXFFVdox44dkqSNGzfKYrHo448/VlRUlDw8PPTll18qIyNDf/vb3xQcHCwfHx/16NFD69evL3Hc5s2b65lnntE999wjX19fhYeHa8mSJSXabNmyRV26dJGnp6e6d++uNWvWyGKxKCUlxdFm7969GjhwoHx8fBQcHKy77rpLP/30k9Ovy68RXgAAqEEmTpyoVatWafny5dq1a5dat26t2NhYnTx50tFm8uTJmj17tlJTU9WpUyfl5eVp0KBBSkpK0u7duxUXF6f4+HhlZWWVOPa8efPUvXt37d69W6NGjdLIkSOVlpYm6fxjm/j4eHXs2FG7du3SzJkzNWnSpBL9T58+rb/85S/q2rWrdu7cqcTERB09elR///vfnX9hfs2oZWw2myHJsNlsri4FAIBKycvLM+rXr2+sWLHCsa2wsNBo2rSp8eyzzxobNmwwJBlr1qz53WNddtllxqJFixzrERERxp133ulYt9vtRpMmTYyXXnrJMAzDeOmll4zGjRsbv/zyi6PN0qVLDUnG7t27DcMwjJkzZxpXX311ifMcOnTIkGSkpaX9oc98QWW+v7nzAgBADZGRkaGioiJdfvnljm3169dXz549lZqa6tjWvXv3Ev3y8vL0yCOPKDIyUgEBAfLx8VFqamqpOy+dOnVy/NlisSgkJETHjh2TJKWlpalTp07y9PR0tOnZs2eJ/nv27NGGDRvk4+PjWNq1a+eovbrUnhE+AADUEQ0aNCix/sgjj2jdunWaO3euWrduLS8vL910000qLCws0a5+/fol1i0Wi+x2e4XPm5eXp/j4eM2ZM6fUvtDQ0Ep8gj+H8AIAQA3RqlUrubu7a/PmzYqIiJAkFRUVaceOHRo7duxF+23evFlDhw7V9ddfL+l8yMjMzKzUudu2bav//Oc/KigokIeHhyQ5Bgpf0K1bN61atUrNmzd36RtOPDYCAKCGaNCggUaOHKlHH31UiYmJ2rdvn0aMGKEzZ85o+PDhF+3Xpk0bvfvuu0pJSdGePXt0++23V+qOiiRHn/vuu0+pqan65JNPNHfuXEn/e335wQcf1MmTJ3Xbbbdpx44dysjI0CeffKJhw4apuLj4j3/wSnJqePn8888VHx+vpk2bymKxaM2aNeW2v/AK2G+XnJwcZ5YJAECNMXv2bN14442666671K1bN6Wnp+uTTz5Rw4YNL9pn/vz5atiwoWJiYhQfH6/Y2Fh169atUuf18/PT+++/r5SUFHXp0kVTp07VtGnTJMkxDqZp06bavHmziouLdfXVV6tjx44aO3asAgICfndK/6pkMQzDcNbBP/74Y23evFlRUVG64YYbtHr1ag0ePPii7Tdu3Kh+/fopLS2txARzTZo0qfBFyc3Nlb+/v2w2G5PUAQDwJ6xYsULDhg2TzWaTl5eX7Ha7fvjhB+Xl5cnHx0cRERFVFloq8/3t1AdWAwcO1MCBAyvdr0mTJgoICKj6ggAAwEW99tpratmypS655BLt2bNHkyZN0t///nd5eXlp3759SkxMVG5urqO9n5+f4uLi1L59+2qts0aOeenSpYtCQ0P117/+VZs3by63bUFBgXJzc0ssAACg8nJycnTnnXcqMjJS48aN080336wlS5Zo3759evvtt0t9x+bm5urtt9/Wvn37qrXOGhVeQkNDtXjxYq1atUqrVq1SWFiY+vbtq127dl20z6xZs+Tv7+9Y+EVpAAD+mIkTJyozM1Nnz57VwYMHtWDBAnl6eioxMbHcfomJiZUeIPxnOHXMS4kTWSy/O+alLH369FF4eLhef/31MvcXFBSooKDAsX7hVykZ8wIAwJ938OBBLV++/Hfb3X333WrRosUfPk+NGfNSFXr27Kkvv/zyovs9PDwc76MDAICqlZeXV6XtqkKNemxUlpSUlGqdtQ8AAPyPj49PlbarCk6985KXl6f09HTH+sGDB5WSkqJGjRopPDxcU6ZMUXZ2tl577TVJ0sKFC9WiRQtddtllOnv2rF555RV99tln+vTTT51ZJgAAuIiIiAj5+fmV+0KMn5+fY0bg6uDU8LJz507169fPsT5+/HhJ55+LJSQk6MiRIyV+NKqwsFATJkxQdna2vL291alTJ61fv77EMQAAQPWxWq2Ki4vT22+/fdE2cXFxtWeSOldgkjoAAKqes+d5qVUDdgEAgOu1b99e7dq1c9oMu5VBeAEAABVitVr/1OvQVVaHqwsAAACoDMILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILADhB3759NXbsWFeXAdRKhBcAAGAqhBcAAGAqhBcAcJJz585p9OjR8vf3V2BgoJ544gkZhiFJev3119W9e3f5+voqJCREt99+u44dO+bou3HjRlksFiUlJal79+7y9vZWTEyM0tLSHG0yMjL0t7/9TcHBwfLx8VGPHj20fv36EjU0b95czzzzjO655x75+voqPDxcS5YsKdFm0qRJuvTSS+Xt7a2WLVvqiSeeUFFRkROvDPDnEF4AwEmWL1+uevXqafv27frnP/+p+fPn65VXXpEkFRUVaebMmdqzZ4/WrFmjzMxMDR06tNQxpk6dqnnz5mnnzp2qV6+e7rnnHse+vLw8DRo0SElJSdq9e7fi4uIUHx+vrKysEseYN2+eunfvrt27d2vUqFEaOXJkiRDk6+urhIQE7du3T//85z+1dOlSLViwwDkXBagKRi1js9kMSYbNZnN1KQDqsD59+hiRkZGG3W53bJs0aZIRGRlZZvsdO3YYkoyff/7ZMAzD2LBhgyHJWL9+vaPNhx9+aEgyfvnll4ue97LLLjMWLVrkWI+IiDDuvPNOx7rdbjeaNGlivPTSSxc9xnPPPWdERUX9/ocEqlBlvr+deufl888/V3x8vJo2bSqLxaI1a9b8bp+NGzeqW7du8vDwUOvWrZWQkODMEgHAaXr37i2LxeJYj46O1oEDB1RcXKzk5GTFx8crPDxcvr6+6tOnjySVumvSqVMnx59DQ0MlyfF4KS8vT4888ogiIyMVEBAgHx8fpaamlnsMi8WikJCQEo+o3nrrLV1++eUKCQmRj4+PHn/88VLHAGoSp4aX/Px8de7cWS+88EKF2h88eFDXXHON+vXrp5SUFI0dO1b33nuvPvnkE2eWCQDV6uzZs4qNjZWfn59WrFihHTt2aPXq1ZKkwsLCEm3r16/v+POFIGS32yVJjzzyiFavXq1nnnlGX3zxhVJSUtSxY8dyj3HhOBeOsXXrVt1xxx0aNGiQPvjgA+3evVtTp04tdQygJqnnzIMPHDhQAwcOrHD7xYsXq0WLFpo3b54kKTIyUl9++aUWLFig2NhYZ5UJAE6xbdu2EutfffWV2rRpo/379+vEiROaPXu2wsLCJEk7d+6s9PE3b96soUOH6vrrr5d0/k5MZmZmpY6xZcsWRUREaOrUqY5tP/zwQ6VrAapTjRqwu3XrVg0YMKDEttjYWG3duvWifQoKCpSbm1tiAYCaICsrS+PHj1daWprefPNNLVq0SGPGjFF4eLjc3d21aNEiff/991q7dq1mzpxZ6eO3adNG7777rlJSUrRnzx7dfvvtjjsqlTlGVlaWVq5cqYyMDD3//POOu0BATVWjwktOTo6Cg4NLbAsODlZubq5++eWXMvvMmjVL/v7+juXCf8UAgKsNGTJEv/zyi3r27KkHH3xQY8aM0X333aegoCAlJCTonXfeUfv27TV79mzNnTu30sefP3++GjZsqJiYGMXHxys2NlbdunWr1DGuu+46jRs3TqNHj1aXLl20ZcsWPfHEE5WuBahOFsP476QDzj6RxaLVq1dr8ODBF21z6aWXatiwYZoyZYpj20cffaRrrrlGZ86ckZeXV6k+BQUFKigocKzn5uYqLCxMNptNfn5+VfoZAKC2sduLlZ36rfJOn5JPQENdEnmZrFY3V5eFOig3N1f+/v4V+v526piXygoJCdHRo0dLbDt69Kj8/PzKDC6S5OHhIQ8Pj+ooDwBqlQPbtuizhCXKO/mTY5tPo0D9Zeh9atMrxoWVAeWrUY+NoqOjlZSUVGLbunXrFB0d7aKKAKB2OrBti9bOf6ZEcJGkvJM/ae38Z3Rg2xYXVQb8PqeGl7y8PKWkpCglJUXS+VehU1JSHPMHTJkyRUOGDHG0f+CBB/T9999r4sSJ2r9/v1588UW9/fbbGjdunDPLBIA6xW4v1mcJS8pts2H5EtntxdVUEVA5Tg0vO3fuVNeuXdW1a1dJ0vjx49W1a1dNmzZNknTkyJESEyG1aNFCH374odatW6fOnTtr3rx5euWVV3hNGgCqUHbqt6XuuPzWzyd+Unbqt9VUEVA5Th3z0rdvX5U3Hris2XP79u2r3bt3O7EqAKjb8k6fqtJ2QHWrUWNeAADO5xPQsErbAdWN8AIAdcwlkZfJp1FguW18GwfqksjLqqkioHIILwBQx1itbvrL0PvKbdPv7vuY7wU1FuEFAOqgNr1idN34x0rdgfFtHKjrxj/GPC+o0WrUJHUAgOrTpleMWvXoxQy7MB3CCwDUYVarm8Iu6+TqMoBK4bERAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwFcILAAAwlVobXsLDw51+joSEBAUEBDj9PAAA4H9qbXhJTk52dQkAAMAJam14CQoKcnUJwO/q27evxo4d6+oyAMBUamR4SUxM1BVXXKGAgAA1btxY1157rTIyMiRJmZmZslgsevfdd9WvXz95e3urc+fO2rp1a4lj/Pqx0ZNPPqkuXbro1VdfVXh4uHx8fDRq1CgVFxfr2WefVUhIiJo0aaKnn366xDHmz5+vjh07qkGDBgoLC9OoUaOUl5fn/AsAAAAuqkaGl/z8fI0fP147d+5UUlKSrFarrr/+etntdkebqVOn6pFHHlFKSoouvfRS3XbbbTp37txFj5mRkaGPP/5YiYmJevPNN/Xvf/9b11xzjX788Udt2rRJc+bM0eOPP65t27Y5+litVj3//PP69ttvtXz5cn322WeaOHGiUz87AAD4HYYJHD9+3JBkfPPNN8bBgwcNScYrr7zi2P/tt98akozU1FTDZrMZkgx/f3/H/unTpxve3t5Gbm6uY1tsbKzRvHlzo7i42LGtbdu2xqxZsy5axzvvvGM0btzYsb5s2bIS5wHKk5eXZ9x1111GgwYNjJCQEGPu3LlGnz59jDFjxhiGYRgnT5407rrrLiMgIMDw8vIy4uLijO+++67EMZYsWWI0a9bM8PLyMgYPHmzMmzePv4MAaoUL3982m+1329bIOy8HDhzQbbfdppYtW8rPz0/NmzeXJGVlZTnadOrUyfHn0NBQSdKxY8cueszmzZvL19fXsR4cHKz27dvLarWW2PbrY6xfv179+/fXJZdcIl9fX9111106ceKEzpw586c/I+qeRx99VJs2bdJ7772nTz/9VBs3btSuXbsc+4cOHaqdO3dq7dq12rp1qwzD0KBBg1RUVCRJ2rx5sx544AGNGTNGKSkp+utf/1rqUScA1AU1MrzEx8fr5MmTWrp0qbZt2+Z4lFNYWOhoU79+fcefLRaLJJV4rPRbv25/oU9Z2y4cIzMzU9dee606deqkVatWKTk5WS+88EKpOoCKyMvL07///W/NnTtX/fv3V8eOHbV8+XLHo84DBw5o7dq1euWVV3TllVeqc+fOWrFihbKzs7VmzRpJ0qJFizRw4EA98sgjuvTSSzVq1CgNHDjQhZ8KAFyjxoWXEydOKC0tTY8//rj69++vyMhInTp1qtrrSE5Olt1u17x589S7d29deumlOnz4cLXXgdohIyNDhYWF6tWrl2Nbo0aN1LZtW0lSamqq6tWrV2J/48aN1bZtW6WmpkqS0tLS1LNnzxLH/e06ANQF9VxdwG81bNhQjRs31pIlSxQaGqqsrCxNnjy52uto3bq1ioqKtGjRIsXHx2vz5s1avHhxtdcBAABKqnF3XqxWq1auXKnk5GR16NBB48aN03PPPVftdXTu3Fnz58/XnDlz1KFDB61YsUKzZs2q9jpQO7Rq1Ur169cv8TbbqVOn9N1330mSIiMjde7cuRL7L9yFbN++vSSpbdu22rFjR4nj/nYdAOoCi2EYhquLqEq5ubny9/eXzWaTn5+fq8sBHEaOHKmPP/5Yr776qpo0aaKpU6fqs88+0/Dhw7Vw4UINHjxYBw4c0MsvvyxfX19NnjxZ6enp2rdvn+rXr6/Nmzfrqquu0nPPPaf4+Hh99tlnmjp1qoqLi13yaBUAqlJlvr+r5c7LCy+8oObNm8vT01O9evXS9u3bL9o2ISFBFoulxOLp6VkdZZbLbjeUnXZK3+3IUXbaKdnttSrzoRo899xzuvLKKxUfH68BAwboiiuuUFRUlGP/smXLFBUVpWuvvVbR0dEyDEMfffSRY2D55ZdfrsWLF2v+/Pnq3LmzEhMTNW7cuBrxzwcAVCen33l56623NGTIEC1evFi9evXSwoUL9c477ygtLU1NmjQp1T4hIUFjxoxRWlra/4q0WBQcHFyh8znjzkvG7mP64q0Dyj9d4NjWIMBDV97SRq26lv4MgDMYdkMFB22y/1woq6+7PFr4677779P+/fv1xRdfuLo8APhTKvP97fQBu/Pnz9eIESM0bNgwSdLixYv14Ycf6tVXX73oQFyLxaKQkBBnl1YhGbuPKfHlvaW2558uUOLLexV3fwcCDJzul70/6fT7GXrh0+W6qkUPedX31KbDO7U8cblefOlFV5cHANXKqeGlsLBQycnJmjJlimOb1WrVgAEDSv0W0a/l5eUpIiJCdrtd3bp10zPPPKPLLruszLYFBQUqKPjfHZHc3Nwqq99uN/TFWwfKbfPl2wfUonOQrFZLlZ0X+LVf9v6kE/85/7r0niP7tXj7m8orPKMI/6aa8ZeHdUfvwa4tEACqmVPDy08//aTi4uJSj3yCg4O1f//+Mvu0bdtWr776qjp16iSbzaa5c+cqJiZG3377rZo1a1aq/axZszRjxgyn1H/kwOkSj4rKkneqQEcOnNYlbRs6pQbUbYbd0On3MxzrLw0u/Xf99Pvfy7N9Y1kI0ADqiBr3qnR0dLSGDBmiLl26qE+fPnr33XcVFBSkl19+ucz2U6ZMkc1mcyyHDh2qslryc8sPLpVtB1RWwUGbim3lz+hcbCtQwUFbNVUEAK7n1DsvgYGBcnNz09GjR0tsP3r0aIXHtNSvX19du3ZVenp6mfs9PDzk4eHxp2stSwO/ih23ou2AyrL/XLGfoqhoOwCoDZx658Xd3V1RUVFKSkpybLPb7UpKSlJ0dHSFjlFcXKxvvvnG8eOL1Sm0TYAaBJQfTHwaeii0TUD1FIQ6x+rrXqXtAKA2cPpjo/Hjx2vp0qVavny5UlNTNXLkSOXn5zvePhoyZEiJAb1PPfWUPv30U33//ffatWuX7rzzTv3www+69957nV1qKVarRVfe0qbcNlf8vQ2DdeE0Hi385eZffjBx8/eQRwv/aqoIAFzP6a9K33LLLTp+/LimTZumnJwcdenSRYmJiY5BvFlZWbJa/5ehTp06pREjRignJ0cNGzZUVFSUtmzZ4pgivbq16tpEcfd3KDXPi09DD13xd+Z5gXNZrBYFxLdyvG1UloD4lgzWBVCn8PMAFWS3G+ffPsotUAO/84+KuOOC6nJhnpdfD9518/dQQHxLeXUIdGFlAFA1atQkdbWF1WrhdWi4jFeHQHm2b1xqhl3uuACoiwgvgElYrBZ5tgpwdRkA4HI1bp4XAACA8hBeAACAqRBeAACAqRBeAACAqRBeAACAqRBeAACAqRBeAACAqRBeAACAqRBeAJhKQkKCAgICXF0GABcivAAAAFMhvAAAAFMhvACoMomJibriiisUEBCgxo0b69prr1VGRoYkKTMzUxaLRStXrlRMTIw8PT3VoUMHbdq0ydF/48aNslgs+vDDD9WpUyd5enqqd+/e2rt3b7nnfe+999StWzd5enqqZcuWmjFjhs6dO+fUzwrAdQgvAKpMfn6+xo8fr507dyopKUlWq1XXX3+97Ha7o82jjz6qCRMmaPfu3YqOjlZ8fLxOnDhR4jiPPvqo5s2bpx07digoKEjx8fEqKioq85xffPGFhgwZojFjxmjfvn16+eWXlZCQoKefftqpnxWACxm1jM1mMyQZNpvN1aUAdd7x48cNScY333xjHDx40JBkzJ4927G/qKjIaNasmTFnzhzDMAxjw4YNhiRj5cqVjjYnTpwwvLy8jLfeesswDMNYtmyZ4e/v79jfv39/45lnnilx3tdff90IDQ114icDUNUq8/1dz6XJCUCtcuDAAU2bNk3btm3TTz/95LjjkpWVpfbt20uSoqOjHe3r1aun7t27KzU1tcRxft2mUaNGatu2bak2F+zZs0ebN28ucaeluLhYZ8+e1ZkzZ+Tt7V1lnw9AzUB4AVBl4uPjFRERoaVLl6pp06ay2+3q0KGDCgsLnXbOvLw8zZgxQzfccEOpfZ6enk47LwDXIbwAqBInTpxQWlqali5dqiuvvFKS9OWXX5Zq99VXX+mqq66SJJ07d07JyckaPXp0qTbh4eGSpFOnTum7775TZGRkmeft1q2b0tLS1Lp166r8OABqMMILgCrRsGFDNW7cWEuWLFFoaKiysrI0efLkUu1eeOEFtWnTRpGRkVqwYIFOnTqle+65p0Sbp556So0bN1ZwcLCmTp2qwMBADR48uMzzTps2Tddee63Cw8N10003yWq1as+ePdq7d6/+8Y9/OOOjAnAx3jYCUCWsVqtWrlyp5ORkdejQQePGjdNzzz1Xqt3s2bM1e/Zsde7cWV9++aXWrl2rwMDAUm3GjBmjqKgo5eTk6P3335e7u3uZ542NjdUHH3ygTz/9VD169FDv3r21YMECRUREOOVzAnA9i2EYhquLqEq5ubny9/eXzWaTn5+fq8sB8F+ZmZlq0aKFdu/erS5dupTZZuPGjerXr59OnTrFTwAAdUxlvr95bATAtIrtxdp1bJeOnzmuIO8gdWvSTW5WN1eXBcDJCC8ATGn9D+s1e/tsHT1z1LEt2DtYk3tO1oCIAS6sDICz8dgIgOms/2G9xm8cL0Ml//VlkUWSNL/vfAIMYDKV+f5mwC4AUym2F2v29tmlgoskx7Y52+eo2F5c3aUBqCaEFwCmsuvYrhKPin7LkKGcMznadWxXNVYFoDoRXgCYyvEzx6u0HQDzIbwAMJUg76AqbQfAfAgvAEylW5NuCvYOdgzO/S2LLArxDlG3Jt2quTIA1YXwAsBU3Kxumtzz/M8O/DbAXFif1HMS870AtVi1hJcXXnhBzZs3l6enp3r16qXt27eX2/6dd95Ru3bt5OnpqY4dO+qjjz6qjjIBmMSAiAGa33e+mng3KbE92DuY16SBOsDpk9S99dZbGj9+vBYvXqxevXpp4cKFio2NVVpampo0aVKq/ZYtW3Tbbbdp1qxZuvbaa/XGG29o8ODB2rVrlzp06ODscgGYxICIAeoX1o8ZdoE6yOmT1PXq1Us9evTQv/71L0mS3W5XWFiYHnrooTJ/cfaWW25Rfn6+PvjgA8e23r17q0uXLlq8ePHvno9J6gAAMJ8aM0ldYWGhkpOTNWDA/27hWq1WDRgwQFu3bi2zz9atW0u0l87/auzF2hcUFCg3N7fEAgAAai+nhpeffvpJxcXFCg4OLrE9ODhYOTk5ZfbJycmpVPtZs2bJ39/fsYSFhVVN8QAAoEYy/dtGU6ZMkc1mcyyHDh1ydUkAAMCJnDpgNzAwUG5ubjp6tORU3kePHlVISEiZfUJCQirV3sPDQx4eHlVTMAAAqPGceufF3d1dUVFRSkpKcmyz2+1KSkpSdHR0mX2io6NLtJekdevWXbQ9AACoW5z+qvT48eN19913q3v37urZs6cWLlyo/Px8DRs2TJI0ZMgQXXLJJZo1a5YkacyYMerTp4/mzZuna665RitXrtTOnTu1ZMkSZ5cKAABMwOnh5ZZbbtHx48c1bdo05eTkqEuXLkpMTHQMys3KypLV+r8bQDExMXrjjTf0+OOP67HHHlObNm20Zs0a5ngBAACSqmGel+rGPC8AAJhPjZnnBQAAoKoRXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKkQXgAAgKk4NbycPHlSd9xxh/z8/BQQEKDhw4crLy+v3D59+/aVxWIpsTzwwAPOLBMAAJhIPWce/I477tCRI0e0bt06FRUVadiwYbrvvvv0xhtvlNtvxIgReuqppxzr3t7eziwTAACYiNPCS2pqqhITE7Vjxw51795dkrRo0SINGjRIc+fOVdOmTS/a19vbWyEhIc4qDQAAmJjTHhtt3bpVAQEBjuAiSQMGDJDVatW2bdvK7btixQoFBgaqQ4cOmjJlis6cOeOsMgEAgMk47c5LTk6OmjRpUvJk9eqpUaNGysnJuWi/22+/XREREWratKm+/vprTZo0SWlpaXr33XfLbF9QUKCCggLHem5ubtV8AAAAUCNVOrxMnjxZc+bMKbdNamrqHy7ovvvuc/y5Y8eOCg0NVf/+/ZWRkaFWrVqVaj9r1izNmDHjD58PAACYS6XDy4QJEzR06NBy27Rs2VIhISE6duxYie3nzp3TyZMnKzWepVevXpKk9PT0MsPLlClTNH78eMd6bm6uwsLCKnx8AABgLpUOL0FBQQoKCvrddtHR0Tp9+rSSk5MVFRUlSfrss89kt9sdgaQiUlJSJEmhoaFl7vfw8JCHh0eFjwcAAMzNaQN2IyMjFRcXpxEjRmj79u3avHmzRo8erVtvvdXxplF2drbatWun7du3S5IyMjI0c+ZMJScnKzMzU2vXrtWQIUN01VVXqVOnTs4qFQAAmIhTJ6lbsWKF2rVrp/79+2vQoEG64oortGTJEsf+oqIipaWlOd4mcnd31/r163X11VerXbt2mjBhgm688Ua9//77ziwTAACYiMUwDMPVRVSl3Nxc+fv7y2azyc/Pz9XlAACACqjM9ze/bQQAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEzFaeHl6aefVkxMjLy9vRUQEFChPoZhaNq0aQoNDZWXl5cGDBigAwcOOKtEAABgQk4LL4WFhbr55ps1cuTICvd59tln9fzzz2vx4sXatm2bGjRooNjYWJ09e9ZZZQIAAJOxGIZhOPMECQkJGjt2rE6fPl1uO8Mw1LRpU02YMEGPPPKIJMlmsyk4OFgJCQm69dZbK3S+3Nxc+fv7y2azyc/P78+WDwAAqkFlvr9rzJiXgwcPKicnRwMGDHBs8/f3V69evbR169aL9isoKFBubm6JBQAA1F41Jrzk5ORIkoKDg0tsDw4Oduwry6xZs+Tv7+9YwsLCnFonAABwrUqFl8mTJ8tisZS77N+/31m1lmnKlCmy2WyO5dChQ9V6fgAAUL3qVabxhAkTNHTo0HLbtGzZ8g8VEhISIkk6evSoQkNDHduPHj2qLl26XLSfh4eHPDw8/tA5AQCoKoZh6P7779f//d//6dSpU9q9e3e5318Xs3HjRvXr10+nTp2q8Nu6dU2lwktQUJCCgoKcUkiLFi0UEhKipKQkx//Zubm52rZtW6XeWAIAwBUSExOVkJCgjRs3qmXLlgoMDPxDx4mJidGRI0fk7+8vqeIvvtQlThvzkpWVpZSUFGVlZam4uFgpKSlKSUlRXl6eo027du20evVqSZLFYtHYsWP1j3/8Q2vXrtU333yjIUOGqGnTpho8eLCzygQAoEpkZGQoNDRUMTExCgkJUb16Je8PFBYWVug47u7uCgkJkcVicUaZtYLTwsu0adPUtWtXTZ8+XXl5eeratau6du2qnTt3OtqkpaXJZrM51idOnKiHHnpI9913n3r06KG8vDwlJibK09PTWWUCAPCnDR06VA899JCysrJksVjUvHlz9e3bV6NHj9bYsWMVGBio2NhYZWZmymKxKCUlxdH39OnTslgs2rhxo6Tzj40sFotOnz6tjRs3atiwYbLZbI6xpU8++aRLPmNNUqnHRpWRkJCghISEctv8dooZi8Wip556Sk899ZSzygIAoMr985//VKtWrbRkyRLt2LFDbm5uuvnmm7V8+XKNHDlSmzdv/kPHjYmJ0cKFCzVt2jSlpaVJknx8fKqydFNyWngBAKCu8Pf3l6+vr9zc3BwvoEhSmzZt9OyzzzrWMzMzK3Vcd3d3+fv7y2KxlDhuXVdj5nkBAKC2iYqKcnUJtRLhBQAAJ2nQoEGJdav1/Nfur4dNFBUVVWtNtQHhBQCAanJhupEjR444tv168G5Z3N3dVVxc7MyyTIcxLwAAVBMvLy/17t1bs2fPVosWLXTs2DE9/vjj5fZp3ry58vLylJSUpM6dO8vb21ve3t7VVHHNxJ0XAACq0auvvqpz584pKirKMb9ZeWJiYvTAAw/olltuUVBQUIkBwHWVxfjt+8omV5mf1AYAoKYpthvafvCkjv18Vk18PdWzRSO5WWv/hHWV+f7msREAADVE4t4jmvH+Ph2xnXVsC/X31PT49orrEFpOz7qFx0YAANQAiXuPaOR/dpUILpKUYzurkf/ZpcS9Ry7Ss+4hvAAA4GLFdkMz3t+nssZxXNg24/19KrbXqpEefxjhBQAAF9t+8GSpOy6/Zkg6Yjur7QdPVl9RNRjhBQAAFzv288WDyx9pV9sRXgAAcLEmvp5V2q62I7wAAOBiPVs0Uqi/py72QrRF59866tmiUXWWVWMRXgAAcDE3q0XT49tLUqkAc2F9enz7OjHfS0UQXgAAqAHiOoTqpTu7KcS/5KOhEH9PvXRnN+Z5+RUmqQMAoIaI6xCqv7YPqZMz7FYG4QUAgBrEzWpRdKvGri6jRuOxEQAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBWnhZenn35aMTEx8vb2VkBAQIX6DB06VBaLpcQSFxfnrBIBAIAJ1XPWgQsLC3XzzTcrOjpa//73vyvcLy4uTsuWLXOse3h4OKM8AABgUk4LLzNmzJAkJSQkVKqfh4eHQkJCnFARAACoDWrcmJeNGzeqSZMmatu2rUaOHKkTJ06U276goEC5ubklFgAAUHvVqPASFxen1157TUlJSZozZ442bdqkgQMHqri4+KJ9Zs2aJX9/f8cSFhZWjRUDAIDqVqnwMnny5FIDan+77N+//w8Xc+utt+q6665Tx44dNXjwYH3wwQfasWOHNm7ceNE+U6ZMkc1mcyyHDh36w+cHaiKLxaI1a9a4ugwAqDEqNeZlwoQJGjp0aLltWrZs+WfqKXWswMBApaenq3///mW28fDwYFAvAAB1SKXCS1BQkIKCgpxVSyk//vijTpw4odDQ0Go7JwAAqNmcNuYlKytLKSkpysrKUnFxsVJSUpSSkqK8vDxHm3bt2mn16tWSpLy8PD366KP66quvlJmZqaSkJP3tb39T69atFRsb66wygQrr27evHnroIY0dO1YNGzZUcHCwli5dqvz8fA0bNky+vr5q3bq1Pv74Y0efTZs2qWfPnvLw8FBoaKgmT56sc+fOlTjmww8/rIkTJ6pRo0YKCQnRk08+WW4d06dPV2hoqL7++mtJ0pdffqkrr7xSXl5eCgsL08MPP6z8/HxJ0lNPPaUOHTqUOkaXLl30xBNPVMFVAQAXMJzk7rvvNiSVWjZs2OBoI8lYtmyZYRiGcebMGePqq682goKCjPr16xsRERHGiBEjjJycnEqd12azGZIMm81WhZ8GMIw+ffoYvr6+xsyZM43vvvvOmDlzpuHm5mYMHDjQWLJkifHdd98ZI0eONBo3bmzk5+cbP/74o+Ht7W2MGjXKSE1NNVavXm0EBgYa06dPL3FMPz8/48knnzS+++47Y/ny5YbFYjE+/fRTRxtJxurVqw273W6MHj3aaN68uXHgwAHDMAwjPT3daNCggbFgwQLju+++MzZv3mx07drVGDp0qGEYhnHo0CHDarUa27dvdxxv165dhsViMTIyMqrnwgFABVTm+9tiGIbhsuTkBLm5ufL395fNZpOfn5+ry0Et0rdvXxUXF+uLL76QJBUXF8vf31833HCDXnvtNUlSTk6OQkNDtXXrVr3//vtatWqVUlNTZbFYJEkvvviiJk2aJJvNJqvVWuqYktSzZ0/95S9/0ezZsyWdH7D7zjvvaPXq1dq9e7fWrVunSy65RJJ07733ys3NTS+//LKj/5dffqk+ffooPz9fnp6eGjRokJo3b64XX3xRkvTwww/rm2++0YYNG5x/0QCggirz/V2jXpUGarpOnTo5/uzm5qbGjRurY8eOjm3BwcGSpGPHjik1NVXR0dGO4CJJl19+ufLy8vTjjz+WeUxJCg0N1bFjx0psGzdunLZt26bPP//cEVwkac+ePUpISJCPj49jiY2Nld1u18GDByVJI0aM0JtvvqmzZ8+qsLBQb7zxhu65554quBoA4BpOm2EXqI3q169fYt1isZTYdiGo2O32P3XM3/b/61//qjfffFOffPKJ7rjjDsf2vLw83X///Xr44YdLHTc8PFySFB8fLw8PD61evVru7u4qKirSTTfdVOH6AKCmIbwAThIZGalVq1bJMAxHqNm8ebN8fX3VrFmzSh3ruuuuU3x8vG6//Xa5ubnp1ltvlSR169ZN+/btU+vWrS/at169err77ru1bNkyubu769Zbb5WXl9cf/2AA4GI8NgKcZNSoUTp06JAeeugh7d+/X++9956mT5+u8ePHy2qt/D96119/vV5//XUNGzZM//d//ydJmjRpkrZs2aLRo0crJSVFBw4c0HvvvafRo0eX6Hvvvffqs88+U2JiIo+MAJged14AJ7nkkkv00Ucf6dFHH1Xnzp3VqFEjDR8+XI8//vgfPuZNN90ku92uu+66S1arVTfccIM2bdqkqVOn6sorr5RhGGrVqpVuueWWEv3atGmjmJgYnTx5Ur169fqzHw0AXIq3jYA6wDAMtWnTRqNGjdL48eNdXQ4AlFKZ72/uvAC1lFFcrDM7k5WTnq7Vu3YpJydHw4YNc3VZAPCnEV6AWij300919JlZOpeTo/Zp+9XQzU1PtblUbjt2SFdf7eryAOBPIbwAtUzup58qe8xY6b9PhPe1befYlz1mrPTPhfIjwAAwMd42AmoRo7hYR5+Z5QguJXee33b0mVkyiouruTIAqDqEF6AWObMzWedyci7ewDB0LidHZ3YmV19RAFDFCC9ALXLu+PEqbQcANRHhBahF6gUFVWk7AKiJCC9ALeLdPUr1QkKkX/0YZAkWi+qFhMi7e1T1FgYAVYjwAtQiFjc3BT825b8rvwkw/10PfmyKLG5u1VwZAFQdwgtQy/hdfbUu+edC1QsOLrG9XnCwLuE1aQC1APO8ALWQ39VXy7d///NvHx0/rnpBQfLuHsUdFwC1AuEFqKUsbm5q0Kunq8sAgCrHYyMAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqTgsvmZmZGj58uFq0aCEvLy+1atVK06dPV2FhYbn9zp49qwcffFCNGzeWj4+PbrzxRh09etRZZQIAAJNxWnjZv3+/7Ha7Xn75ZX377bdasGCBFi9erMcee6zcfuPGjdP777+vd955R5s2bdLhw4d1ww03OKtMAABgMhbDMIzqOtlzzz2nl156Sd9//32Z+202m4KCgvTGG2/opptuknQ+BEVGRmrr1q3q3bv3754jNzdX/v7+stls8vPzq9L6AQCAc1Tm+7tax7zYbDY1atToovuTk5NVVFSkAQMGOLa1a9dO4eHh2rp1a5l9CgoKlJubW2IBAAC1V7WFl/T0dC1atEj333//Rdvk5OTI3d1dAQEBJbYHBwcrJyenzD6zZs2Sv7+/YwkLC6vKsgEAQA1T6fAyefJkWSyWcpf9+/eX6JOdna24uDjdfPPNGjFiRJUVL0lTpkyRzWZzLIcOHarS4wMAgJqlXmU7TJgwQUOHDi23TcuWLR1/Pnz4sPr166eYmBgtWbKk3H4hISEqLCzU6dOnS9x9OXr0qEJCQsrs4+HhIQ8PjwrXDwAAzK3S4SUoKEhBQUEVapudna1+/fopKipKy5Ytk9Va/o2eqKgo1a9fX0lJSbrxxhslSWlpacrKylJ0dHRlSwUAALWQ08a8ZGdnq2/fvgoPD9fcuXN1/Phx5eTklBi7kp2drXbt2mn79u2SJH9/fw0fPlzjx4/Xhg0blJycrGHDhik6OrpCbxoBAIDar9J3Xipq3bp1Sk9PV3p6upo1a1Zi34W3s4uKipSWlqYzZ8449i1YsEBWq1U33nijCgoKFBsbqxdffNFZZQIAAJOp1nleqgPzvAAAYD41dp4XAACAP4vwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwApjEk08+qS5duri6DABwOcILAAAwFcILUI3sdrueffZZtW7dWh4eHgoPD9fTTz8tSZo0aZIuvfRSeXt7q2XLlnriiSdUVFQkSUpISNCMGTO0Z88eWSwWWSwWJSQkuPCTAIDr1HN1AUBdMmXKFC1dulQLFizQFVdcoSNHjmj//v2SJF9fXyUkJKhp06b65ptvNGLECPn6+mrixIm65ZZbtHfvXiUmJmr9+vWSJH9/f1d+FABwGYthGIari6hKubm58vf3l81mk5+fn6vLARx+/vlnBQUF6V//+pfuvffe320/d+5crVy5Ujt37pR0fszLmjVrlJKS4uRKAaD6Veb7mzsvQDVJTU1VQUGB+vfvX+b+t956S88//7wyMjKUl5enc+fOEcABoAxOG/OSmZmp4cOHq0WLFvLy8lKrVq00ffp0FRYWltuvb9++jmf6F5YHHnjAWWUC1cbLy+ui+7Zu3ao77rhDgwYN0gcffKDdu3dr6tSpv/vPCwDURU6787J//37Z7Xa9/PLLat26tfbu3asRI0YoPz9fc+fOLbfviBEj9NRTTznWvb29nVUmUG3atGkjLy8vJSUllXpstGXLFkVERGjq1KmObT/88EOJNu7u7iouLq6WWgGgJnNaeImLi1NcXJxjvWXLlkpLS9NLL730u+HF29tbISEhzioNcAlPT09NmjRJEydOlLu7uy6//HIdP35c3377rdq0aaOsrCytXLlSPXr00IcffqjVq1eX6N+8eXMdPHhQKSkpatasmXx9feXh4eGiTwMArlOtr0rbbDY1atTod9utWLFCgYGB6tChg6ZMmaIzZ85ctG1BQYFyc3NLLEBN9cQTT2jChAmaNm2aIiMjdcstt+jYsWO67rrrNG7cOI0ePVpdunTRli1b9MQTT5Toe+ONNyouLk79+vVTUFCQ3nzzTRd9CgBwrWp72yg9PV1RUVGaO3euRowYcdF2S5YsUUREhJo2baqvv/5akyZNUs+ePfXuu++W2f7JJ5/UjBkzSm3nbSOYnr1Y+mGLlHdU8gmWImIkq5urqwIAp6jM20aVDi+TJ0/WnDlzym2Tmpqqdu3aOdazs7PVp08f9e3bV6+88kplTqfPPvtM/fv3V3p6ulq1alVqf0FBgQoKChzrubm5CgsLI7zA3PatlRInSbmH/7fNr6kUN0dqf53r6gIAJ3FqeDl+/LhOnDhRbpuWLVvK3d1dknT48GH17dtXvXv3VkJCgqzWyj2pys/Pl4+PjxITExUbG/u77ZnnBaa3b6309hBJv/1H03L+f/7+GgEGQK3j1HlegoKCFBQUVKG22dnZ6tevn6KiorRs2bJKBxdJjgm5QkNDK90XMB178fk7LqWCi/67zSIlTpbaXcMjJAB1ltMG7GZnZ6tv374KDw/X3Llzdfz4ceXk5CgnJ6dEm3bt2mn79u2SpIyMDM2cOVPJycnKzMzU2rVrNWTIEF111VXq1KmTs0oFao4ftpR8VFSKIeVmn28HAHWU016VXrdundLT05Wenq5mzZqV2HfhSVVRUZHS0tIcbxO5u7tr/fr1WrhwofLz8xUWFqYbb7xRjz/+uLPKBGqWvKNV2w4AaiF+2wioSQ5+IS2/9vfb3f2B1OJK59cDANWkMt/f1TrPC4DfERFz/q2iC4NzS7FIfpecbwcAdRThBahJrG7nX4eWVDrA/Hc9bjaDdQHUaYQXoKZpf93516H9fvOGnV9TXpMGADlxwC6AP6H9dedfh2aGXQAohfAC1FRWNwblAkAZeGwEAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMpdbNsGsYhqTzP60NAADM4cL39oXv8fLUuvDy888/S5LCwsJcXAkAAKisn3/+Wf7+/uW2sRgViTgmYrfbdfjwYfn6+spisVS4X25ursLCwnTo0CH5+fk5scK6g2tatbieVY9rWrW4nlWvLl1TwzD0888/q2nTprJayx/VUuvuvFitVjVr1uwP9/fz86v1f0GqG9e0anE9qx7XtGpxPateXbmmv3fH5QIG7AIAAFMhvAAAAFMhvPyXh4eHpk+fLg8PD1eXUmtwTasW17PqcU2rFtez6nFNy1brBuwCAIDajTsvAADAVAgvAADAVAgvAADAVAgvAADAVAgvF3HdddcpPDxcnp6eCg0N1V133aXDhw+7uixTyszM1PDhw9WiRQt5eXmpVatWmj59ugoLC11dmqk9/fTTiomJkbe3twICAlxdjum88MILat68uTw9PdWrVy9t377d1SWZ1ueff674+Hg1bdpUFotFa9ascXVJpjZr1iz16NFDvr6+atKkiQYPHqy0tDRXl1WjEF4uol+/fnr77beVlpamVatWKSMjQzfddJOryzKl/fv3y2636+WXX9a3336rBQsWaPHixXrsscdcXZqpFRYW6uabb9bIkSNdXYrpvPXWWxo/frymT5+uXbt2qXPnzoqNjdWxY8dcXZop5efnq3PnznrhhRdcXUqtsGnTJj344IP66quvtG7dOhUVFenqq69Wfn6+q0urMXhVuoLWrl2rwYMHq6CgQPXr13d1Oab33HPP6aWXXtL333/v6lJMLyEhQWPHjtXp06ddXYpp9OrVSz169NC//vUvSed/Ey0sLEwPPfSQJk+e7OLqzM1isWj16tUaPHiwq0upNY4fP64mTZpo06ZNuuqqq1xdTo3AnZcKOHnypFasWKGYmBiCSxWx2Wxq1KiRq8tAHVRYWKjk5GQNGDDAsc1qtWrAgAHaunWrCysDymaz2SSJf2f+CuGlHJMmTVKDBg3UuHFjZWVl6b333nN1SbVCenq6Fi1apPvvv9/VpaAO+umnn1RcXKzg4OAS24ODg5WTk+OiqoCy2e12jR07Vpdffrk6dOjg6nJqjDoVXiZPniyLxVLusn//fkf7Rx99VLt379ann34qNzc3DRkyRDxl+5/KXk9Jys7OVlxcnG6++WaNGDHCRZXXXH/kmgKovR588EHt3btXK1eudHUpNUo9VxdQnSZMmKChQ4eW26Zly5aOPwcGBiowMFCXXnqpIiMjFRYWpq+++krR0dFOrtQcKns9Dx8+rH79+ikmJkZLlixxcnXmVNlrisoLDAyUm5ubjh49WmL70aNHFRIS4qKqgNJGjx6tDz74QJ9//rmaNWvm6nJqlDoVXoKCghQUFPSH+trtdklSQUFBVZZkapW5ntnZ2erXr5+ioqK0bNkyWa116qZfhf2Zv6OoGHd3d0VFRSkpKckxqNRutyspKUmjR492bXGAJMMw9NBDD2n16tXauHGjWrRo4eqSapw6FV4qatu2bdqxY4euuOIKNWzYUBkZGXriiSfUqlUr7rr8AdnZ2erbt68iIiI0d+5cHT9+3LGP/9L947KysnTy5EllZWWpuLhYKSkpkqTWrVvLx8fHtcXVcOPHj9fdd9+t7t27q2fPnlq4cKHy8/M1bNgwV5dmSnl5eUpPT3esHzx4UCkpKWrUqJHCw8NdWJk5Pfjgg3rjjTf03nvvydfX1zEWy9/fX15eXi6uroYwUMrXX39t9OvXz2jUqJHh4eFhNG/e3HjggQeMH3/80dWlmdKyZcsMSWUu+OPuvvvuMq/phg0bXF2aKSxatMgIDw833N3djZ49expfffWVq0syrQ0bNpT5d/Huu+92dWmmdLF/Xy5btszVpdUYzPMCAABMhYEHAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVAgvAADAVP4fcpVHT6a17YgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_batch():\n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)\n",
    "\n",
    "    for i in random_index:\n",
    "        random_inputs.append(np.eye(voc_size)[skip_grams[i][0]])  # target\n",
    "        random_labels.append(skip_grams[i][1])  # context word\n",
    "\n",
    "    return random_inputs, random_labels\n",
    "\n",
    "# Model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        # W and WY is not Transpose Relationship\n",
    "        self.W = nn.Linear(voc_size, embedding_size, bias=False)  # voc_size > embedding_size Weight\n",
    "        self.WT = nn.Linear(embedding_size, voc_size, bias=False)  # embedding_size > voc_size Weight\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X : [batch_size, voc_size]\n",
    "        hidden_layer = self.W(X)  # hidden_layer : [batch_size, embedding_size]\n",
    "        output_layer = self.WT(hidden_layer)\n",
    "        return output_layer\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    batch_size = 2\n",
    "    embedding_size = 2\n",
    "\n",
    "    sentences = [\"apple banana fruit\", \"banana orange fruit\", 'orange banana fruit', 'dog cat animal', 'cat monkey animal', 'monkey dog animal']\n",
    "\n",
    "    word_sequence = \" \".join(sentences).split()\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w : i for i, w in enumerate(word_list)}\n",
    "    voc_size = len(word_list)\n",
    "\n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    for i in range(1, len(word_sequence) - 1):\n",
    "        target = word_dict[word_sequence[i]]\n",
    "        context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]\n",
    "        for w in context:\n",
    "            skip_grams.append([target, w])\n",
    "    \n",
    "    model = Word2Vec()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(15000):\n",
    "        input_batch, target_batch = random_batch()\n",
    "        input_batch = torch.Tensor(input_batch)\n",
    "        target_batch = torch.LongTensor(target_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_batch)\n",
    "\n",
    "        # output : [batch size, voc size], target_batch : [batch_size] (LongTensor, not one-hot)\n",
    "        loss = criterion(output, target_batch)\n",
    "        if (epoch+1)%1000 == 0:\n",
    "            print('Epoch {}, cost = {:.6f}'.format(epoch+1, loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    for i, label in enumerate(word_list):\n",
    "        W, WT = model.parameters()\n",
    "        x, y = W[0][i].item(), W[1][i].item()\n",
    "\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords=\"offset points\", ha=\"right\", va=\"bottom\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링\n",
    "Word2Vec의 출력층에는 소프트맥스 함수를 지난 단어 집합의 크기의 벡터와 실제값인 원핫 벡터와의 오차를 구하고 이로부터 임베딩 벡터 값을 업데이트합니다. 만약 단어 집합의 크기가 수만 이상에 달한다면 이 작업은 굉장히 무거운 작업이므로, Word2Vec은 꽤나 학습하기에 무거운 모델이 됩니다.\n",
    "\n",
    "Word2Vec은 역전파 과정에서 모든 단어의 임베딩 벡터값의 업데이트를 수행하지만, 만약 현재 집중하고 있는 중심 단어와 주변 단어가 '강아지'와 '고양이', '귀여운'과 같은 단어라면, 사실 이 단어들과 별 연관 관계가 없는 '돈가스'나 '컴퓨터'와 같은 수많은 단어의 임베딩 벡터값까지 업데이트하는 것은 비효율적입니다.\n",
    "\n",
    "네거티브 샘플링은 **Word2Vec이 학습 과정에서 전체 단어 집합이 아니라 일부 단어 집합에만 집중할 수 있도록 하는 방법**입니다. 가령 현재 집중하고 있는 주변 단어가 '고양이', '귀여운'이라고 해봅시다. 여기에 '돈가스', '컴퓨터', '회의실'과 같은 단어 집합에서 무작위로 선택된 주변 단어가 아닌 단어들을 일부 가져옵니다. 이렇게 하나의 중심 단어에 대해서 전체 단어 집합보다 훨씬 작은 단어 집합을 만들어 놓고 마지막 단계를 이진 분류 문제로 변환합니다. 주변 단어들을 긍정(positive), 랜덤으로 샘플링 된 단어들을 부정(negative)으로 레이블링한다면 이진 분류 문제를 위한 데이터셋이 됩니다. 이는 기존의 단어 집합의 크기만큼의 선택지를 두고 다중 클래스 분류 문제를 풀던 Word2Vec보다 훨씬 연산량에서 효율적입니다.\n",
    "\n",
    "## 네거티브 샘플링 Skip-gram\n",
    "\n",
    "> The fat cat sat on the mat\n",
    "\n",
    "skip-gram은 중심 단어로부터 주변 단어를 예측하는 모델이다. 위와 같은 문장이 있다고 한다면, Skip-Gram은 중심 단어인 cat으로 부터 주변 단어인 The, sat, on을 예측한다. 기존의 Skip-gram은 입력으로 cat이 주어지고, 예측으로 주변 단어가 output으로 나오는 구조이다.\n",
    "\n",
    "하지만 네거티브 샘플링을 사용하는 Skip-Gram(SGNS)는 이와는 다른 접근 방식을 취합니다. 주변단어와 중심단어가 모두 input으로 입력되고, 이 두 단어가 실제로 window size 내에 존재하는 이웃 관계인지 그 확률을 예측한다.\n",
    "\n",
    "기존의 Skip-gram 데이터셋을 SGNS의 데이터셋으로 바꾸는 과정은 아래와 같다.\n",
    "\n",
    "<img src=\"./images_for_markdown/SGtoSGNS.png\">\n",
    "\n",
    "위의 그림에서 좌측의 테이블은 기존의 skip-gram을 학습하기 위한 데이터셋입니다. Skip-gram은 기본적으로 중심 단어를 입력, 주변 단어를 레이블로 합니다. 하지만 SGNS를 학습하고 싶다면, 이 데이터셋을 우측의 테이블과 같이 수정할 필요가 있습니다. 우선, **기존의 Skip-gram 데이터셋에서 중심 단어와 주변 단어를 각각 입력1, 입력2**로 둡니다. 이 둘은 실제로 윈도우 크기 내에서 이웃 관계였으므로, **레이블은 1**로 합니다. 이제 레이블이 0인 샘플들을 준비할 차례입니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/SGNS-data.png\">\n",
    "\n",
    "실제로는 입력1(중심 단어)와 주변 단어 관계가 아닌 단어들을 입력2로 삼기 위해서 **단어 집합에서 랜덤으로 선택한 단어들을 입력2**로 하고, **레이블을 0**으로 합니다. 이제 이 데이터셋은 입력1과 입력2가 실제로 윈도우 크기 내에서 이웃 관계인 경우에는 레이블이 1, 아닌 경우에는 레이블이 0이 됩니다. 그리고 이제 두 개의 임베딩 테이블을 준비합니다. 두 임베딩 테이블은 훈련 데이터의 단어 집합의 크기를 가지므로 크기가 같습니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding_table.png\">\n",
    "\n",
    "두 테이블 중 하나는 입력1인 중심 단어의 룩업 테이블을 위한 임베딩 테이블이고, 하나는 입력2인 주변 단어의 룩업테이블을 위한 임베딩 테이블입니다. 각 단어는 각 임베딩 테이블을 룩업 테이블하여 임베딩 벡터로 변환됩니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding.png\">\n",
    "\n",
    "각 임베딩 테이블을 통해 룩업 테이블 하며 임베딩 벡터로 변환되었다면 그 후의 연산은 매우 간단합니다.\n",
    "\n",
    "<img src=\"./images_for_markdown/embedding_vec_update.png\">\n",
    "\n",
    "중심 단어와 주변 단어의 내적값을 이 모델의 예측값으로 하고, 레이블과의 오차로부터 역전파 하며 중심 단어와 주변 단어의 임베딩 벡터값을 업데이트합니다. 학습 후에는 좌측의 임베딩 행렬을 임베딩 벡터로 사용할 수도 있고, 두 행렬을 더한 후 사용하거나 두 행렬을 연결(concatenate)해서 사용할 수도 있습니다. 아래의 실습에서는 좌측의 행렬을 사용하는 방식을 택했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20뉴스 그룹 데이터셋으로 실습을 진행합니다. \n",
    "\n",
    "해당 실습에서는 하나의 샘플에 최소 2개의 단어가 있어야합니다. 그래야만 중심 단어, 주변 단어의 관계가 성립하며 그렇지 않으면 샘플을 구성할 수 없어 오류가 발생합니다. 전처리 과정에서 지속적으로 이를 만족하지 않는 샘플들을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "documents = dataset.data\n",
    "print(\"총 샘플 수 : \", len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 샘플 수는 11,314개 입니다. 전처리를 진행하며 불필요한 토큰을 제거하고, 소문자화를 통해 정규화를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({\"document\":documents})\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")  # 특수문자 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))  # 길이가 3 이하인 문자들 제거\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().values.any()  # 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.replace(\"\", float(\"NaN\"), inplace=True)  # 빈 값을 결측치로 치환해서 다시 확인\n",
    "news_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  11004\n"
     ]
    }
   ],
   "source": [
    "news_df.dropna(inplace=True)  # 결측치 제거\n",
    "print('총 샘플 수 : ', len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stop_words = stopwords.words(\"english\")\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 :  10961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniconda3\\envs\\mynlp\\lib\\site-packages\\numpy\\lib\\function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)\n",
    "print(\"총 샘플 수 : \", len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {val : key for key, val in word2idx.items()}\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40,\n",
       "  53,\n",
       "  927,\n",
       "  143,\n",
       "  15889,\n",
       "  1684,\n",
       "  546,\n",
       "  279,\n",
       "  871,\n",
       "  12028,\n",
       "  17773,\n",
       "  24007,\n",
       "  29726,\n",
       "  279,\n",
       "  871,\n",
       "  63435,\n",
       "  871,\n",
       "  1128,\n",
       "  1103,\n",
       "  1998,\n",
       "  851,\n",
       "  29727,\n",
       "  913,\n",
       "  731,\n",
       "  20477,\n",
       "  279,\n",
       "  871,\n",
       "  170,\n",
       "  143,\n",
       "  1811,\n",
       "  149,\n",
       "  279,\n",
       "  20478,\n",
       "  17773,\n",
       "  6645,\n",
       "  5710,\n",
       "  76,\n",
       "  63436,\n",
       "  7,\n",
       "  36,\n",
       "  165,\n",
       "  614,\n",
       "  653,\n",
       "  29728,\n",
       "  6911,\n",
       "  24008,\n",
       "  2082,\n",
       "  829,\n",
       "  17774,\n",
       "  1119,\n",
       "  8790,\n",
       "  355,\n",
       "  1072,\n",
       "  15890,\n",
       "  671,\n",
       "  57,\n",
       "  163,\n",
       "  4231,\n",
       "  7206,\n",
       "  1933,\n",
       "  440,\n",
       "  56,\n",
       "  282,\n",
       "  4730,\n",
       "  9275,\n",
       "  2690,\n",
       "  39306],\n",
       " [1283,\n",
       "  429,\n",
       "  3,\n",
       "  52,\n",
       "  6164,\n",
       "  159,\n",
       "  112,\n",
       "  474,\n",
       "  89,\n",
       "  17775,\n",
       "  18,\n",
       "  63,\n",
       "  4731,\n",
       "  2865,\n",
       "  63437,\n",
       "  1042,\n",
       "  402,\n",
       "  39307,\n",
       "  8791,\n",
       "  902,\n",
       "  44,\n",
       "  8328,\n",
       "  316,\n",
       "  13041,\n",
       "  902,\n",
       "  3452,\n",
       "  5923,\n",
       "  533,\n",
       "  18,\n",
       "  87,\n",
       "  4732,\n",
       "  9872,\n",
       "  160,\n",
       "  1403,\n",
       "  120,\n",
       "  151,\n",
       "  5194,\n",
       "  63438,\n",
       "  63439,\n",
       "  17776,\n",
       "  63440,\n",
       "  13041,\n",
       "  903,\n",
       "  63441,\n",
       "  63442,\n",
       "  11172,\n",
       "  17777]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 :  181839\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "\n",
    "print(\"단어 집합의 크기 : \", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링을 통한 데이터셋 구성하기\n",
    "\n",
    "토큰화, 정제, 정규화, 불용어 제거, 정수 인코딩까지 일반적인 전처리 과정을 거쳤습니다. 네거티브 샘플링을 통한 데이터셋을 구성할 차례입니다.\n",
    "\n",
    "이를 위해서는 네커티브 샘플링을 위해서 케라스에서 제공하는 전처리 도구인 skipgrams를 사용합니다. 어떤 전처리가 수행되는지 그 결과를 확인하기 위해서 상위 10개의 뉴스 그룹 샘플에 대해서만 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shame (6911), soldiers (1072)) -> 1\n",
      "(soldiers (1072), 20's (22525)) -> 0\n",
      "(biased. (15889), media (871)) -> 1\n",
      "(commited (8790), dickering (97764)) -> 0\n",
      "(media (871), world. (1128)) -> 1\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플인 skip_grams[0] 내 skipgrams로 형성된 데이터셋 확인\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "        idx2word[pairs[i][0]], pairs[i][0],\n",
    "        idx2word[pairs[i][1]], pairs[i][1],\n",
    "        labels[i]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윈도우 크기 내에서 중심 단어, 주변 단어의 관계를 가지는 경우에는 1의 레이블을 갖도록 하고, 그렇지 않은 경우는 0의 레이블을 가지도록 하여 데이터셋을 구성합니다.\n",
    "\n",
    "이 과정은 각각의 뉴스그룹 샘플에 대해서 동일한 프로세스로 수행됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 :  10\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 : ', len(skip_grams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoded 중 상위 10개의 뉴스그룹 샘플에 대해서만 수행하였으므로 10이 출력됩니다. 그리고 10개의 뉴스그룹 샘플 각각은 수많은 중심 단어, 주변 단어의 쌍으로 된 샘플들을 갖고 있습니다. 첫 번째 뉴스그룹 샘플이 가지고 있는 pairs와 labels의 개수를 출력해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2460\n",
      "2460\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 뉴스그룹 샘플에 대해 수행\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram with Negative Sampling(SGNS) 구현하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼 파라미터인 임베딩 벡터의 차원은 100으로 정하고, 두 개의 임베딩 층을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "# 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype=\"int32\")\n",
    "word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs)\n",
    "\n",
    "# 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype=\"int32\")\n",
    "context_embedding = Embedding(vocab_size, embedding_dim)(c_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 임베딩 테이블은 중심 단어와 주변 단어 각각을 위한 임베딩 테이블이며 각 단어는 임베딩 테이블을 거쳐서 내적을 수행하고, 내적의 결과는 1 또는 0을 예측하기 위해서 시그모이드 함수를 활성화 함수로 거쳐 최종 예측값을 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       18183900    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 100)       18183900    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1, 1)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1)            0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1)            0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,367,800\n",
      "Trainable params: 36,367,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1, ), input_shape=(1, 1))(dot_product)\n",
    "output = Activation(\"sigmoid\")(dot_product)\n",
    "\n",
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "plot_model(model, to_file=\"model3.png\", show_shapes=True, show_layer_names=True, rankdir=\"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for _, elem in enumerate(skip_grams):\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype=\"int32\")\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype=\"int32\")\n",
    "        labels = np.array(elem[1], dtype=\"int32\")\n",
    "        X = [first_elem, second_elem]\n",
    "        Y = labels\n",
    "\n",
    "        loss += model.train_on_batch(X, Y)\n",
    "    print(\"Epoch : {} Loss : {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "with open('vectors.txt', 'w') as f:\n",
    "    f.write(\"{} {}\\n\".format(vocab_size-1, embedding_dim))\n",
    "\n",
    "    vectors = model.get_weights()[0]\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        f.write('{} {}\\n'.format(word, \" \".join(map(str, list(vectors[i, :])))))\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"./vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['soldiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autokeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
